{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "from metaphone import doublemetaphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>METAPHONE_A</th>\n",
       "      <th>METAPHONE_B</th>\n",
       "      <th>REGEX_CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARIA</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>CACIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARMEN</td>\n",
       "      <td>KRMN</td>\n",
       "      <td>KRMN</td>\n",
       "      <td>CACEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOSEFA</td>\n",
       "      <td>JSF</td>\n",
       "      <td>HSF</td>\n",
       "      <td>COCECA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NAME METAPHONE_A METAPHONE_B REGEX_CV\n",
       "0   MARIA          MR          MR    CACIA\n",
       "1  CARMEN        KRMN        KRMN    CACEC\n",
       "2  JOSEFA         JSF         HSF   COCECA"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"resources/export_full_dataset.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Jjuaaannn is transformed to JUAN.\n"
     ]
    }
   ],
   "source": [
    "cREGEX_NOT_REPEATED = re.compile(r\"(.)\\1+\")\n",
    "\n",
    "def pre_processing_token(iToken):\n",
    "    return cREGEX_NOT_REPEATED.sub(r\"\\1\", iToken.upper())\n",
    "\n",
    "vToken = \"Jjuaaannn\"\n",
    "print(f\"Token {vToken} is transformed to {pre_processing_token(vToken)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_text': 'NATALiy DJFISDFNSDF VAÑERO',\n",
       " 'new_text': 'NATALY DESMOND VALERO',\n",
       " 'distances': [{'original_token': 'NATALiy',\n",
       "   'new_token': 'NATALY',\n",
       "   'token_difference': 2.0},\n",
       "  {'original_token': 'DJFISDFNSDF',\n",
       "   'new_token': 'DESMOND',\n",
       "   'token_difference': 11.704699910719626},\n",
       "  {'original_token': 'VAÑERO',\n",
       "   'new_token': 'VALERO',\n",
       "   'token_difference': 1.7320508075688772}]}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cCONSONANTS = \"BCDFGHIJKLMNÑPQRSTVWXZ\"\n",
    "\n",
    "def get_semantic_token(iToken):\n",
    "    vTokenRegex = iToken.upper()\n",
    "    vTokenRegex = vTokenRegex.translate(str.maketrans(cCONSONANTS, \"C\" * len(cCONSONANTS)))\n",
    "    vTokenRegex = cREGEX_NOT_REPEATED.sub(r\"\\1\", vTokenRegex)\n",
    "    return vTokenRegex\n",
    "\n",
    "def get_correct_token(iToken):\n",
    "    vData = df[df[\"NAME\"] == iToken.upper()][\"NAME\"].values.tolist()\n",
    "    if len(vData) > 0:\n",
    "        return vData[0], 0\n",
    "        #return df[df[\"NAME\"] == iToken]\n",
    "    vToken = pre_processing_token(iToken)\n",
    "    vData = df[df[\"NAME\"] == vToken][\"NAME\"].values.tolist()\n",
    "    if len(vData) > 0:\n",
    "        return vData[0], 0.3\n",
    "        #return df[df[\"NAME\"] == vToken]\n",
    "    vData = df.copy()\n",
    "    #print(f\"Processing token: {vToken}.\")\n",
    "    vMetaphoneA, vMetaphoneB = doublemetaphone(vToken)\n",
    "    vMetaphoneB = vMetaphoneB if len(vMetaphoneB) > 0 else vMetaphoneA\n",
    "    #print(f\"Metaphones: {vMetaphoneA} y {vMetaphoneB}.\")\n",
    "    vSemanticRegex = get_semantic_token(iToken)\n",
    "    #print(f\"The REGEX is: {vSemanticRegex}.\")\n",
    "    \n",
    "    vData[\"LEVENSHTEIN_TOKEN\"]  = vData[\"NAME\"].apply(lambda x : Levenshtein.distance(x, iToken))\n",
    "    vData[\"LEVENSHTEIN_META_A\"] = vData[\"METAPHONE_A\"].apply(lambda x : Levenshtein.distance(x, vMetaphoneA))\n",
    "    vData[\"LEVENSHTEIN_META_B\"] = vData[\"METAPHONE_B\"].apply(lambda x : Levenshtein.distance(x, vMetaphoneB))\n",
    "    vData[\"LEVENSHTEIN_REGEX\"]  = vData[\"REGEX_CV\"].apply(lambda x : Levenshtein.distance(x, vSemanticRegex))\n",
    "    \n",
    "    vData[\"LEVENSHTEIN_TOTAL\"] = np.power(vData[\"LEVENSHTEIN_TOKEN\"], 2) + \\\n",
    "        np.power(vData[\"LEVENSHTEIN_META_A\"], 2) + \\\n",
    "        np.power(vData[\"LEVENSHTEIN_META_B\"], 2) + \\\n",
    "        np.power(vData[\"LEVENSHTEIN_REGEX\"], 2)\n",
    "    vData[\"LEVENSHTEIN_TOTAL\"] = np.sqrt(vData[\"LEVENSHTEIN_TOTAL\"])\n",
    "    vData = vData.sort_values(by = \"LEVENSHTEIN_TOTAL\", ascending=True)\n",
    "    vList = vData[0:1][[\"NAME\", \"LEVENSHTEIN_TOTAL\"]].values.tolist()[0]\n",
    "    return vList[0], vList[1]\n",
    "\n",
    "def verify_name(iMalformedName : str):\n",
    "    vArrayTokens = iMalformedName.split(\" \")\n",
    "    vResult = []\n",
    "    for vToken in vArrayTokens:\n",
    "        vNewToken, vDistance = get_correct_token(vToken)\n",
    "        vResult.append({\n",
    "            \"original_token\": vToken,\n",
    "            \"new_token\": vNewToken,\n",
    "            \"token_difference\": vDistance \n",
    "        })\n",
    "    vResult = {\n",
    "        \"original_text\": iMalformedName,\n",
    "        \"new_text\": \" \".join([x[\"new_token\"] for x in vResult]),\n",
    "        \"distances\": vResult\n",
    "    }\n",
    "    return vResult\n",
    "\n",
    "#get_correct_token(\"VALELO\")[0:1][\"NAME\"].values.tolist()[0]\n",
    "verify_name(\"NATALiy DJFISDFNSDF VAÑERO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
